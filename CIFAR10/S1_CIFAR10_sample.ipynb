{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Test Code & Weights - Setting 1 (CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import easydict\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from wideresnet import Wide_ResNet, Wide_ResNet_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Setting\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "args = \\\n",
    "easydict.EasyDict({\"dataset\": 'cifar10',\n",
    "                   \"train_cls\": None,\n",
    "                   \"resumepath\": './weights/setting1/',\n",
    "                   \"filename\": 'sample_weight_ours.pt',\n",
    "                   \"batch_size\": 100,\n",
    "                   \"ood_score\": \"distance\",\n",
    "                   \"experiment\": 0\n",
    "})\n",
    "\n",
    "args.train_cls = np.load('{}known.npy'.format(args.resumepath)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR10 Dataset...\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Select Dataset\n",
    "if args.dataset.lower() == 'cifar10':\n",
    "    print('Loading {} Dataset...'.format(args.dataset.upper()))\n",
    "    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "    transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "    image_shape = (3, 32, 32)\n",
    "    n_class = 10\n",
    "    test_set = torchvision.datasets.CIFAR10(root='/home/openset/data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "elif args.dataset.lower() == 'cifar100':\n",
    "    print('Loading {} Dataset...'.format(args.dataset.upper()))\n",
    "    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "    transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "    image_shape = (3, 32, 32)\n",
    "    n_class = 100\n",
    "    test_set = torchvision.datasets.CIFAR100(root='/home/openset/data', train=False, download=True, transform=transform_test)\n",
    "    \n",
    "elif args.dataset.lower() == 'svhn':\n",
    "    print('Loading {} Dataset...'.format(args.dataset.upper()))\n",
    "    transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    image_shape = (3, 32, 32)\n",
    "    n_class = 10\n",
    "    test_set = torchvision.datasets.SVHN(root='/home/openset/data', split='test', download=True, transform=transform_test)\n",
    "    \n",
    "elif args.dataset.lower() == 'tiny':\n",
    "    print('Loading {} Dataset...'.format(args.dataset.upper()))\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "    n_class = 200\n",
    "    image_shape = (3, 64, 64)\n",
    "    test_set = torchvision.datasets.ImageFolder('/home/openset/data/tiny-imagenet-200/val', transform=transform_test)\n",
    "        \n",
    "else:\n",
    "    raise ValueError(\"Unsupported Dataset \"+args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsets(dataset, train_cls, return_ood=False):\n",
    "    known, unknown = [], []\n",
    "    for i in range(len(dataset)):\n",
    "        current_class = dataset[i][1]\n",
    "        if current_class in train_cls:\n",
    "            known.append(i)\n",
    "        else:\n",
    "            unknown.append(i)\n",
    "\n",
    "    ind = Subset(dataset, known)\n",
    "    ood = Subset(dataset, unknown)\n",
    "    \n",
    "    if return_ood == True:\n",
    "        return ind, ood\n",
    "    else:\n",
    "        return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building In-Class Dataset...: [0, 3, 4, 6, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# Get Subset of Classes\n",
    "print('Building In-Class Dataset...: {}'.format(args.train_cls))\n",
    "if args.experiment == 0:\n",
    "    ood_cls = list(set(range(n_class)) - set(args.train_cls))\n",
    "    ind_test_set, ood_test_set = get_subsets(test_set, args.train_cls, return_ood=True)\n",
    "    \n",
    "else:\n",
    "    ind_test_set = test_set\n",
    "    transform_test = transforms.Compose([#transforms.Resize((32, 32)),\n",
    "                                         #transforms.CenterCrop(32),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean, std)])\n",
    "    \n",
    "    ood_test_set = torchvision.datasets.ImageFolder('/home/openset/ood/iSUN/', transform=transform_test)\n",
    "num_classes = len(args.train_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(num_means, model, shape):\n",
    "    with torch.no_grad():\n",
    "        inp = torch.ones(shape).unsqueeze(0)\n",
    "        penul, _ = model(inp)\n",
    "        dim = penul.shape[-1]\n",
    "    \n",
    "        means = torch.zeros((num_means, dim))\n",
    "        for i in range(num_means):\n",
    "            means[i] = torch.randn(dim)\n",
    "        print(\"Feature Dimension: {}\".format(dim))\n",
    "    return means, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "| Wide-Resnet 40x2\n",
      "Finished: Model Contains 2245958 Parameters\n",
      "Initializing Means...\n",
      "Feature Dimension: 128\n",
      "Saving Initial Parameters...\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "print('Building Model...')\n",
    "model = Wide_ResNet(40, 2, 0.3, num_classes)\n",
    "print(\"Finished: Model Contains {} Parameters\".format(sum([p.numel() for p in model.parameters()])))\n",
    "\n",
    "# Initialize Means (Anchors)\n",
    "print('Initializing Means...')\n",
    "means, dim = get_means(num_classes, model, image_shape)\n",
    "means_np = means.cpu().numpy()\n",
    "    \n",
    "means = torch.tensor(means_np, device=device)\n",
    "inv_cov_stds = torch.log(torch.exp(torch.tensor(1., device=device)) - 1.0)\n",
    "weights = torch.ones((len(means)), device=device)\n",
    "    \n",
    "# Set Initial Parameters\n",
    "print('Saving Initial Parameters...')\n",
    "model = model.to(device)\n",
    "model.initialize(means, inv_cov_stds, weights, grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "if args.resumepath != '':\n",
    "    file = args.resumepath + args.filename\n",
    "    assert os.path.isfile(file)\n",
    "    checkpoint = torch.load(file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test_loader = torch.utils.data.DataLoader(ind_test_set,\n",
    "                                              batch_size=args.batch_size,\n",
    "                                              shuffle=False,                                              \n",
    "                                              num_workers=1,\n",
    "                                              pin_memory=True,\n",
    "                                              drop_last=False)\n",
    "\n",
    "ood_test_loader = torch.utils.data.DataLoader(ood_test_set,\n",
    "                                              batch_size=args.batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=1,\n",
    "                                              pin_memory=True,\n",
    "                                              drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_labels(label_tensor, train_cls, device):\n",
    "    new = []\n",
    "    for i in label_tensor:\n",
    "        new.append(train_cls.index(i))\n",
    "    return torch.tensor(new).to(device)\n",
    "\n",
    "def reduce_labels_sv(label_tensor, train_cls, device):\n",
    "    new = []\n",
    "    for i in label_tensor:\n",
    "        new.append(len(train_cls))\n",
    "    return torch.tensor(new).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-set Classification Acc: 0.9728333333333333\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "score = []\n",
    "true = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in ind_test_loader:\n",
    "        model.eval()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = reduce_labels(y, args.train_cls, device)\n",
    "\n",
    "        z_all, logits = model(x)\n",
    "        \n",
    "        if args.ood_score == 'distance':\n",
    "            distance = torch.norm(z_all.unsqueeze(1) - model.means, p=2, dim=2)**2\n",
    "            min_score, _ = torch.min(distance, dim=1)\n",
    "            logits = -distance/2\n",
    "            \n",
    "        elif args.ood_score == 'energy':\n",
    "            min_score = -torch.logsumexp(logits, dim=1)\n",
    "        \n",
    "        else:\n",
    "            prob = F.softmax(logits, dim=1)\n",
    "            entropy = (prob * torch.log(prob)).sum(1)\n",
    "            min_score, _ = -torch.max(prob, dim=1)\n",
    "            #min_dist = min_dist * torch.norm(z_all, dim=1)\n",
    "            #min_dist = entropy\n",
    "            \n",
    "        preds_all = torch.argmax(logits, dim=1)\n",
    "        count += (preds_all == y).sum()\n",
    "        y_true = np.append(y_true, y.detach().cpu().numpy())\n",
    "        y_pred = np.append(y_pred, preds_all.detach().cpu().numpy())\n",
    "\n",
    "        score = np.append(score, min_score.detach().cpu().numpy())\n",
    "        true = np.append(true, np.zeros_like(min_score.detach().cpu().numpy()))\n",
    "\n",
    "    print(\"Closed-set Classification Acc: {}\".format(int(count.cpu())/len(ind_test_loader.dataset)))\n",
    "\n",
    "    for x, y in ood_test_loader:\n",
    "        model.eval()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = reduce_labels_sv(y, args.train_cls, device)\n",
    "\n",
    "        z_all, logits = model(x)\n",
    "\n",
    "        if args.ood_score == 'distance':\n",
    "            distance = torch.norm(z_all.unsqueeze(1) - model.means, p=2, dim=2)**2\n",
    "            min_score, _ = torch.min(distance, dim=1)\n",
    "            logits = -distance/2\n",
    "            \n",
    "        elif args.ood_score == 'energy':\n",
    "            min_score = -torch.logsumexp(logits, dim=1)\n",
    "        \n",
    "        else:\n",
    "            prob = F.softmax(logits, dim=1)\n",
    "            entropy = (prob * torch.log(prob)).sum(1)\n",
    "            min_score, _ = -torch.max(prob, dim=1)\n",
    "            #min_score = min_score * torch.norm(z_all, dim=1)\n",
    "            #min_score = entropy\n",
    "            \n",
    "        preds_all = torch.argmax(logits, dim=1)\n",
    "        count += (preds_all == y).sum()\n",
    "        y_true = np.append(y_true, y.detach().cpu().numpy())\n",
    "        y_pred = np.append(y_pred, preds_all.detach().cpu().numpy())\n",
    "\n",
    "        score = np.append(score, min_score.detach().cpu().numpy())\n",
    "        true = np.append(true, np.ones_like(min_score.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9446843541666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "print(\"AUROC: {}\".format(roc_auc_score(true, score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSCR at FPR of 10^-1: 0.8685\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn import metrics\n",
    "threshold = np.percentile(score[len(ind_test_loader.dataset):], 10)\n",
    "index = np.where(score > threshold)\n",
    "y_pred2 = copy.deepcopy(y_pred)\n",
    "y_pred2[index] = 6\n",
    "\n",
    "print(\"OSCR at FPR of 10^-1: {}\".format((y_true[:len(ind_test_loader.dataset)] == y_pred2[:len(ind_test_loader.dataset)]).sum()/len(ind_test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonwoo2",
   "language": "python",
   "name": "wonwoo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
